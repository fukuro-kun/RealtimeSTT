# RealtimeSTT Technisches Entwicklungsprotokoll

Dieses Dokument dient als technisches Ged√§chtnis des RealtimeSTT-Projekts. Es ist ein lebendes Dokument, das kontinuierlich aktualisiert wird und folgende Aspekte festh√§lt:

## Zweck
- Dokumentation kritischer technischer Parameter und Konfigurationen
- Archivierung von Implementierungsentscheidungen und deren Begr√ºndungen
- Sammlung von Probleml√∂sungen und technischen Erkenntnissen
- Nachvollziehbarkeit der Entwicklungshistorie

## Verwendung
- Nachschlagewerk f√ºr exakte technische Spezifikationen
- Referenz f√ºr Debugging und Probleml√∂sung
- Vermeidung bereits getesteter, nicht funktionierender Ans√§tze
- Wissensspeicher f√ºr neue Projektmitarbeiter

## Inhaltsverzeichnis

### 1. ‚öôÔ∏è Kritische Konfiguration
- Audio-Verarbeitung
- Voice Activity Detection (VAD)
- Sprachmodelle und KI
- Thread-Management
- X11-Integration

### 2. üí° Technische Erkenntnisse
- Erfolgreiche Implementierungen
- Verworfene Ans√§tze
- Kritische Berechnungen
- Performance-Optimierungen

### 3. üöß Aktuelle Entwicklung
- Bekannte Probleme
- Work in Progress
- N√§chste Schritte
- Aktuelle Experimente

## üéØ Vision
Entwicklung eines robusten, multilingualen Echtzeit-Spracherkennungssystems mit Fokus auf:
- Pr√§zise Spracherkennung f√ºr Deutsch und Englisch
- Minimale Latenz
- Adaptive Sprachpausenerkennung
- Flexible Ausgabemodi

### 1. ‚öôÔ∏è Kritische Konfiguration

### Audio-Verarbeitung

#### Grundlegende Parameter
```python
DEVICE_RATE = 44100    # Hardware-Abtastrate
MODEL_RATE = 16000     # Erforderliche Rate f√ºr VAD und Whisper
CHANNELS = 1           # Mono-Audio
CHUNK_SIZE = 1323      # Berechnet f√ºr exakte 30ms Frames nach Resampling
FORMAT = paFloat32     # 32-bit Float Audio-Format
```

#### Frame-Verarbeitung
- Exakte Frame-Gr√∂√üe: 30ms bei 16kHz = 480 Samples
- Frame-Gr√∂√üe hat gr√∂√üeren Einfluss auf VAD-Qualit√§t als Abtastrate
- Jeder Frame muss EXAKT diese Gr√∂√üe haben
- Zu kleine oder gro√üe Frames werden von WebRTC VAD abgelehnt
- Frame-L√§nge muss VOR der VAD-Verarbeitung gepr√ºft werden
- Unvollst√§ndige Frames am Ende des Audio-Chunks √ºberspringen

#### Byte-Konvertierung und Normalisierung
- Audio-Samples m√ºssen als 16-bit Integer vorliegen
- 2 Bytes pro Sample (int16) = 960 Bytes pro Frame
- Wichtig: Korrekte Normalisierung auf [-32768, 32767]
- Normalisierung VOR Resampling verbessert Audioqualit√§t
- Schwellwert bei 0.001 f√ºr Audio-Pegel

#### Hardware-Timing und Puffer
- USB-Mikrofon-spezifische Verz√∂gerungen
- Pr√§zise Frame-Synchronisation notwendig
- Kompensation von Hardware-Jitter
- √úberlappende Audio-Fenster trotz h√∂herem Ressourcenverbrauch n√∂tig
- 25-Sekunden-Limit verhindert √ºberraschenderweise Speicherlecks
- Mehr Puffer-Kopien k√∂nnen Performance verbessern (Cache-Alignment)

### Sprachmodelle und KI

#### Deutsch (primeline/whisper-large-v3-turbo-german)
- Accuracy: 98.2%
- Optimiert f√ºr deutsche Dialekte
- Performance-Monitoring f√ºr Ladezeiten
- Thread-Status-Tracking bei Modellwechsel
- Schnelle Inferenz durch Turbo-Optimierung

#### Englisch (openai/whisper-small)
- Accuracy: 99.18%
- Geringer Ressourcenverbrauch
- Effiziente GPU-Nutzung
- Kontinuierliches Performance-Profiling
- Ideal f√ºr Echtzeit-Verarbeitung

#### Modell-Management
- Vorladestrategie statt Lazy Loading (schneller trotz h√∂herem initialen Speicherverbrauch)
- Permanenter Modell-Cache
- Optimierte CUDA-Nutzung
- Float16-Pr√§zision wo m√∂glich
- Beide Modelle beim Start laden
- Permanent im Speicher halten
- Schnelles Switching ohne Ladezeiten
- Keine dynamische Nachladelogik

### Voice Activity Detection (VAD)

#### Grundeinstellungen
```python
VAD_FRAME_MS = 30          # Frame-Dauer in Millisekunden
MIN_SPEECH_DURATION = 0.3   # Minimale Dauer f√ºr Spracherkennung
POST_SPEECH_SILENCE = {
    "incomplete": 2.0,    # F√ºr "..." am Ende
    "complete": 0.45,     # F√ºr ".", "!", "?"
    "unclear": 0.7       # F√ºr unklare Enden
}
VAD_MODE = 2               # Mittlere Aggressivit√§t (0-3)
```

#### Adaptive Pausenerkennung
- **Kurze Pause**: 0.45s nach Satzende (".", "!", "?")
- **Mittlere Pause**: 0.7s bei unklarem Ende
- **Lange Pause**: 2.0s bei Unterbrechungen ("...")

#### Optimierte Konfiguration
- Aggressivit√§tslevel 2 f√ºr beste Balance
- Pr√§zise Frame-Ausrichtung f√ºr zuverl√§ssige Erkennung
- Schwellwertbasierte Aktivierung
- Reduzierte False-Positives durch angepasste Parameter

### Thread-Management
- Thread-sichere Queues f√ºr Audio-Verarbeitung
- Robustes Exception-Handling
- Saubere Ressourcen-Freigabe
- Automatische Buffer-Bereinigung

#### Verworfene Threading-Modelle
1. **Single-Thread mit Callback**
   - Zu hohe Latenz
   - Audio-Dropouts bei Modellwechsel
   - Blockierung der UI

2. **Thread-Pool Ansatz**
   - Overhead durch Task-Scheduling
   - Komplexe Synchronisation
   - Ressourcenverschwendung

3. **Async/Await Modell**
   - Nicht kompatibel mit PortAudio
   - Komplexe Error-Propagation
   - Schwierige Ressourcenverwaltung

#### Aktuelles Modell
- Dedizierte Threads f√ºr:
  * Audio-Capture (realtime-priority)
  * VAD-Processing
  * Whisper-Inference
  * UI-Updates
- Ringpuffer f√ºr Thread-Kommunikation
- Explizite Synchronisationspunkte
- Robuste Exception-Propagation

### X11-Integration
#### Grundkonfiguration
- xdotool f√ºr Cursor-Steuerung
- X11-Display-Environment erforderlich
- Root-Rechte nicht notwendig

#### Kritische Parameter
- Cursor-Update-Rate: 75ms (experimentell ermittelt)
- X11-Display-Buffer-Size: 8192 bytes
- Event-Queue-Size: 256 events

#### Bekannte Einschr√§nkungen
- Funktioniert nur unter X11, nicht Wayland
- Root-Window muss zug√§nglich sein
- Multi-Monitor Setup erfordert spezielle Konfiguration

#### Cursor-Management
- Pr√§zise Positionierung via xdotool
- Koordinaten-Mapping zwischen Screens
- Event-basierte Position-Updates
- Throttling zur Vermeidung von Screen-Tearing

#### Error-Handling
- X11-Connection-Loss Recovery
- Display-Buffer-Overflow Protection
- Auto-Reconnect bei Connection-Drop
- Graceful Fallback bei fehlenden Berechtigungen

## 2. üí° Technische Erkenntnisse

### Implementierungs-Evolution
#### Standard Version (Original Whisper)
- Wichtige Erkenntnisse:
  * Direkte Whisper-Integration zu langsam f√ºr Echtzeit
  * Hardware-Anforderungen nicht praktikabel
  * Wertvolle Basis f√ºr Optimierungsstrategien

#### USB Version (realtimestt_test_usb.py)
- Kritische Learnings:
  * √úberlappende Audio-Fenster notwendig gegen Wortverluste
  * 25-Sekunden-Limit pro Block verhindert Memory-Leaks
  * Hardware-Timing kritisch f√ºr USB-Mikrofone
  * Adaptive Pausenerkennung verbessert Nutzererlebnis

#### HF Version (realtimestt_test_hf.py)
- Wichtige Erkenntnisse:
  * Vorladestrategie besser als Lazy Loading
  * Terminal-GUI erschwert Debugging erheblich
  * L√∂sung: Separates Logging-System implementiert
  * Modell-Wechsel erzeugt Audio-Dropouts

### Architektur-Evolution
- **Urspr√ºnglicher Ansatz**: 
  * Batch-basierte Verarbeitung
  * Feste Puffergr√∂√üe
  * Statische Pausenerkennung

- **Neue Architektur** (basierend auf realtimestt_test_usb.py):
  * Kontinuierlicher Audio-Stream
  * Chunk-basierte Echtzeit-Verarbeitung
  * Dynamische Puffer-Anpassung
  * Adaptive VAD-Integration
  * Verbesserte Thread-Synchronisation

#### Vorteile der neuen Architektur
1. **Performance**:
   * Geringere Latenz durch Stream-Verarbeitung
   * Effizientere Ressourcennutzung
   * Bessere CPU-Auslastung

2. **Zuverl√§ssigkeit**:
   * Stabilere USB-Mikrofon-Erkennung
   * Robustere Audio-Capture
   * Verbesserte Fehlerbehandlung

3. **Flexibilit√§t**:
   * Einfachere Integration neuer Features
   * Modulare Komponenten
   * Bessere Testbarkeit

#### Implementierungsdetails
```python
# Neue Stream-basierte Verarbeitung
def audio_callback(self, in_data, frame_count, time_info, status):
    """Callback f√ºr kontinuierliche Audio-Verarbeitung"""
    if not self._running:
        return (None, pyaudio.paComplete)
    
    # Echtzeit-Verarbeitung statt Batch
    audio_data = np.frombuffer(in_data, dtype=np.float32)
    is_speech = self.is_speech(in_data)
    
    if is_speech:
        self.audio_buffer.append(in_data)
    else:
        # Adaptive Pausenerkennung
        self.process_buffer()
    
    return (in_data, pyaudio.paContinue)
```

#### Kritische Aspekte
- Thread-Safety in der Audio-Verarbeitung
- Korrekte Buffer-Synchronisation
- Pr√§zise Timing-Kontrolle
- Speichermanagement bei kontinuierlichem Streaming

### Frame-Verarbeitung
#### Grundlegende Parameter
```python
DEVICE_RATE = 44100    # Hardware-Abtastrate
MODEL_RATE = 16000     # Erforderliche Rate f√ºr VAD und Whisper
CHANNELS = 1           # Mono-Audio
CHUNK_SIZE = 1323      # Berechnet f√ºr exakte 30ms Frames nach Resampling
FORMAT = paFloat32     # 32-bit Float Audio-Format
```

#### Frame-Gr√∂√üen-Berechnung
Der wichtigste Aspekt ist die Einhaltung exakter 30ms Frame-Gr√∂√üen f√ºr WebRTC VAD:

1. WebRTC VAD ben√∂tigt exakt 480 Samples pro Frame bei 16kHz (30ms)
2. Um dies nach dem Resampling zu erreichen, brauchen wir:
   ```
   480 * (44100/16000) = 1323 Samples bei 44.1kHz
   ```
3. Nach dem Resampling von 1323 Samples bei 44.1kHz erhalten wir exakt 480 Samples bei 16kHz

#### Audio-Format-Spezifikationen
- **Eingabeformat**: Float32 (-1.0 bis 1.0)
- **VAD-Format**: Int16 (-32768 bis 32767)
- **Normalisierung**: Schwellwert bei 0.001 f√ºr Audio-Pegel

#### Frame-Verarbeitung
1. **Frame-Gr√∂√üen-Pr√§zision**
   - Exakte Frame-Gr√∂√üen sind kritisch f√ºr VAD
   - Falsche Resampling-Verh√§ltnisse f√ºhren zu Frame-Fehlausrichtung
   - Puffergr√∂√üen m√ºssen das Resampling-Verh√§ltnis ber√ºcksichtigen
   - Frame-L√§nge muss VOR der VAD-Verarbeitung gepr√ºft werden
   - Unvollst√§ndige Frames am Ende des Audio-Chunks √ºberspringen

2. **Audio-Format-Behandlung**
   - Eingang: Float32 (-1.0 bis 1.0)
   - VAD: Int16 (-32768 bis 32767)
   - Korrekte Normalisierung ist essentiell
   - Wichtig: Korrekte Normalisierung auf [-32768, 32767]

3. **Performance-Optimierungen**
   - Minimierung von Pufferkopien
   - Effizientes Numpy-Array-Slicing f√ºr Frame-Extraktion
   - Vorherige Normalisierung der Audio-Daten
   - Reduzierte False-Positives durch angepasste Schwellwerte
   - Effizientes Resampling
   - Echtzeitverarbeitungs-Anforderungen

4. **Kontraintuitive Optimierungen**
   - Frame-Gr√∂√üe hat gr√∂√üeren Einfluss auf VAD-Qualit√§t als Abtastrate
   - Normalisierung VOR Resampling verbessert Audioqualit√§t
   - Mehr Puffer-Kopien k√∂nnen Performance verbessern (Cache-Alignment)
   - Speech-Ratio muss √ºber ALLE g√ºltigen Frames berechnet werden
   - √úberlappende Audio-Fenster trotz h√∂herem Ressourcenverbrauch n√∂tig
   - 25-Sekunden-Limit verhindert √ºberraschenderweise Speicherlecks
   - Vorladestrategie schneller als Lazy Loading trotz h√∂herem initialen Speicherverbrauch

### Audio-Stream-Management
#### Kritische Erkenntnisse
- Chunk-basierte Verarbeitung mit pr√§zisem Timing
- Adaptive Pausenerkennung f√ºr nat√ºrliche Segmentierung
- √úberlappende Fenster gegen Wortverluste
- Buffer-Management mit 25-Sekunden-Limit

#### Hardware-Timing
- USB-Mikrofon-spezifische Verz√∂gerungen
- Pr√§zise Frame-Synchronisation notwendig
- Kompensation von Hardware-Jitter
- Robuste Error-Handling f√ºr Timing-Probleme

### Debugging und Probleml√∂sung
#### Debugging-Tipps
1. √úberwachung der Audio-Pegel in Debug-Logs
2. √úberpr√ºfung der Frame-Gr√∂√üen nach Resampling
3. Kontrolle der VAD-Frame-Ausrichtung
4. Validierung der Abtastraten-Konvertierungen

#### H√§ufige Probleme und L√∂sungen
1. **Frame-Fehlausrichtung**
   - Symptom: Keine Spracherkennung
   - Ursache: Falsche Chunk-Gr√∂√üe
   - L√∂sung: Exakte Chunk-Gr√∂√üe (1323 Samples)

2. **Audio-Pegel-Probleme**
   - Symptom: Falsch-Negative
   - Ursache: Fehlerhafte Normalisierung
   - L√∂sung: Korrekte Float32-zu-Int16-Konvertierung

3. **Resampling-Artefakte**
   - Symptom: Schlechte Erkennungsqualit√§t
   - Ursache: Ungenaues Resampling
   - L√∂sung: Korrektes Verh√§ltnis und Puffergr√∂√üe

### Implementierungserfolge
- Erfolgreiche Tests mit USB-Mikrofon
- Pr√§zise Spracherkennung f√ºr Deutsch
- Robuste Frame-Verarbeitung
- Minimale Latenz
- Zuverl√§ssige Sprachsegmentierung

## 3. üöß Aktuelle Entwicklung

### Bekannte Probleme
1. **Terminal-Fenster-Anpassung**
   - Problem: Terminalausgabe √ºberschreibt sich bei mehrzeiligem Text
   - Getestete Ans√§tze:
     * ANSI-Escape-Sequenzen f√ºr Zeilenl√∂schung (unzuverl√§ssig)
     * tput-Befehle f√ºr Fensteranpassung (funktioniert nicht √ºberall)
     * Curses-Library (vielversprechend, aber komplexere Implementation)
   - Aktueller Stand: Curses-basierte L√∂sung in Entwicklung

2. **Audio-Processing**
   - ALSA-Warnungen bei Programmstart
   - Gelegentliche Verz√∂gerungen bei Sprachmoduswechsel
   - Speichernutzung bei langen Aufnahmen
   - Transkriptionen werden nicht angezeigt
     * Vermutung: Problem in der Verarbeitungskette
     * Logging zeigt erfolgreiche Erkennung, aber keine Anzeige

### Work in Progress
1. **Audio-Qualit√§tskontrolle**
   - Implementierung von Audio-Level-Schwellwerten
   - Optimierung der Normalisierung
   - Validierung der Resampling-Qualit√§t

2. **Whisper-Integration**
   - Validierung der Modell-Ausgabe
   - Fehlerbehandlung bei der Transkription
   - Performance-Monitoring

3. **Textformatierung**
   - Getrennte Zust√§ndigkeiten:
     * `process_text()`: VAD-Parameter-Steuerung
     * `format_output_text()`: Anzeigeformatierung
   - Wichtig: Original-Text f√ºr VAD-Logik beibehalten
   - Formatierung erst nach VAD-Verarbeitung
   - Sorgf√§ltige Behandlung von Sonderzeichen ("...")

### N√§chste Schritte
1. **Kurzfristig**
   - Feinjustierung der VAD-Parameter
   - Implementation der adaptiven Pausenerkennung
   - Debug-Logging in der Verarbeitungskette

2. **Mittelfristig**
   - Audio-Level-Meter
   - Detaillierte Audio-Diagnostik
   - Offline-Test-Modus
   - Performance-Profiling

3. **Langfristig**
   - Wayland Support evaluieren
   - Performance-Optimierungen
   - Weitere Sprach-Modelle

### Aktuelle Experimente
- Audio-Level-Meter Tests
- VAD-Parameter Optimierung
- Modell-Performance-Tests

## 4. üîÑ Git und Versionierung

#### Sprachrichtlinien
- **Code und Commits**
  - Variablen, Funktionen und Klassen auf Englisch
  - Commit-Messages auf Englisch
  - Verbessert Universalit√§t und erleichtert potenzielle Pull Requests

- **Dokumentation**
  - README.md: Zweisprachig (Deutsch/Englisch)
  - Technische Dokumentation (DEVELOPMENT.md, README_Benchmark.md): Prim√§r Deutsch
  - Code-Kommentare: Deutsch (lokale Entwicklung)

- **Pull Request Vorbereitung**
  - Betroffene Dokumentation ins Englische √ºbersetzen
  - Code-Kommentare der betroffenen Dateien ins Englische √ºbersetzen
  - Nur f√ºr Dateien, die Teil des Pull Requests sind

Diese Richtlinien erm√∂glichen:
- Effiziente lokale Entwicklung in Deutsch
- Universelle Code-Verst√§ndlichkeit
- Einfache Integration von Pull Requests
- Zug√§nglichkeit f√ºr internationale Entwickler
